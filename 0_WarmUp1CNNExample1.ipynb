{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akutayaydin/Magnimind-5.1-DeepLearning/blob/main/0_WarmUp1CNNExample1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmy5qTKlB2CI"
      },
      "source": [
        "# CNN Example 1\n",
        "For this example, we have images of cars and flowers, which have been divided into training and testing sets, and we have to build a CNN that identifies whether an image is a car or a flower."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lgp8guPB2CM"
      },
      "source": [
        "### Step 1: Import the numpy library and the necessary Keras libraries and classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "upl626WiB2CN"
      },
      "outputs": [],
      "source": [
        "# Import the Libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "from tensorflow import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYEzxW4VB2CO"
      },
      "source": [
        "### Step 2: Now, set a seed and initiate the model with the `Sequential` class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "afwVGvUBB2CP"
      },
      "outputs": [],
      "source": [
        "#set a seed\n",
        "seed = 1\n",
        "np.random.seed(seed)\n",
        "random.set_seed(seed)\n",
        "\n",
        "# Initialising the CNN\n",
        "classifier = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj0rBoXqB2CP"
      },
      "source": [
        "### Step 3: Add the first layer of the CNN, set the input shape to (64, 64, 3), the dimension of each image, and set the activation function as a ReLU:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Conv2D(10,kernel_size =2, activation = 'relu',input_shape = (64,64,3)))"
      ],
      "metadata": {
        "id": "AgeuksX0-HMg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzoUpnCSB2CP"
      },
      "source": [
        "### Step 4: Now, add the pooling layer with the image size as 2x2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(MaxPool2D(pool_size =(2,2)))"
      ],
      "metadata": {
        "id": "9V-N27VN9B4Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEWIVnACB2CQ"
      },
      "source": [
        "### Step 5: Flatten the output of the pooling layer by adding a flattening layer to the CNN model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qxsUjB8nB2CQ"
      },
      "outputs": [],
      "source": [
        "classifier.add(Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqt_0VFFB2CQ"
      },
      "source": [
        "### Step 6: Add the first Dense layer of the MLP. \n",
        "Here, 128 is the output of the number of nodes. As a good practice, 128 is good to get started. activation is relu. As a good practice, the power of two is preferred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-j1PqTa8B2CQ"
      },
      "outputs": [],
      "source": [
        "classifier.add(Dense(128,activation = 'relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGhBSPmHB2CQ"
      },
      "source": [
        "### Step 7: Add the output layer of the MLP.\n",
        "This is a binary classification problem, so the size is 1 and the activation is `sigmoid`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mwvnRNVZB2CR"
      },
      "outputs": [],
      "source": [
        "classifier.add(Dense(1,activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9dg60CvB2CR"
      },
      "source": [
        "### Step 8: Compile the network\n",
        "Use an adam optimizer and compute the accuracy during the training process "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "9aOmePUeBNJC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhIQ1s91B2CR"
      },
      "source": [
        "### Step 9: Create training and test data generators. \n",
        "- Rescale the training and test images by `1/255` so that all the values are between `0` and `1`.\n",
        "- Set these parameters for the training data generators only \n",
        " - `shear_range=0.2`, `zoom_range=0.2`, and `horizontal_flip=True`\n",
        " \n",
        " - https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfolwzTsRuF7",
        "outputId": "168352aa-32d1-4aaa-e96a-6b62a69b743e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "t7sXo40sB2CS"
      },
      "outputs": [],
      "source": [
        "mypath='/content/gdrive/My Drive/Google Colab Folder/'\n",
        "mypath_testdata = '/content/gdrive/My Drive/Google Colab Folder/train'\n",
        "mypath_testdata_flower = '/content/gdrive/My Drive/Google Colab Folder/train/car/'\n",
        "mypath_validationdata = '/content/gdrive/My Drive/Google Colab Folder/train/flower/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check for any file corruption\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "for name in os.listdir(mypath_testdata):\n",
        "  dir = os.path.join(mypath_testdata, name)\n",
        "  if os.path.isdir(dir):\n",
        "    print('Dir name:' + str(name))\n",
        "    for fname in os.listdir(dir):\n",
        "      try:   \n",
        "        img = Image.open(str(dir) + '/'+ str(fname))\n",
        "        img.verify()  # verify that it is, in fact an image\n",
        "      except:\n",
        "        print('Bad file: ' + str(fname))"
      ],
      "metadata": {
        "id": "5JJwUJWiNGxJ",
        "outputId": "a088481a-2eae-4d5a-9081-2b149f9c33f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dir name:car\n",
            "Bad file: car1115.jpg\n",
            "Dir name:flower\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.utils import array_to_img, img_to_array, load_img"
      ],
      "metadata": {
        "id": "29x1XRL9VRk0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define batch size here\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1. /255,\n",
        "    shear_range =0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1. /255)"
      ],
      "metadata": {
        "id": "9pZWwYUzPFiI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RqwiPw1B2CR"
      },
      "source": [
        "### Step 10: Create a training set from the training set folder.\n",
        "'training_set' is the folder where our data has been placed. Our CNN model has an image size of `64x64`, so the same size should be passed here too. `batch_size` is the number of images in a single batch, which is `32`. `Class_mode` is set to binary since we are working on binary classifiers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train data generation starts here\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    #str(mypath)+'train', # traget directory\n",
        "    directory = '/content/gdrive/My Drive/Google Colab Folder/train',\n",
        "    target_size = (64,64), #resize all images\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF_vCK-lB_UD",
        "outputId": "5cde466b-2db8-439d-be1c-6d525abef2ce"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1569 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Llh-3cHRB2CS"
      },
      "source": [
        "### Step 11: Repeat step 10 for the test set \n",
        "while setting the folder to the location of the test images, that is, 'test_set'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gel5EYa7B2CS",
        "outputId": "1ba300b2-6a7d-4bd0-c3e2-62863a229042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 387 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "#Test data generation starts here\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    #str(mypath)+'test',\n",
        "    directory = '/content/gdrive/My Drive/Google Colab Folder/test',\n",
        "    target_size = (64,64),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv8y1u9ZB2CS"
      },
      "source": [
        "### Step 12: Finally, fit the data. \n",
        "Set the `steps_per_epoch` to `STEP_SIZE_TRAIN` and the `validation_steps` to `STEP_SIZE_TEST`. \n",
        "\n",
        "Why do we need `steps_per_epoch` ?\n",
        "\n",
        "Keep in mind that a Keras data generator is meant to loop infinitely — it should never return or exit.\n",
        "\n",
        "Since the function is intended to loop infinitely, Keras has no ability to determine when one epoch starts and a new epoch begins.\n",
        "\n",
        "Therefore, we compute the `steps_per_epoch` value as the total number of training data points divided by the batch size. Once Keras hits this step count it knows that it’s a new epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GsNWVdQkB2CT",
        "outputId": "a860f9bd-1c4a-4254-dfb0-274eb994be64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 14s 4s/step - loss: 0.6671 - accuracy: 0.6562 - val_loss: 0.7560 - val_accuracy: 0.4375\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 12s 4s/step - loss: 0.6496 - accuracy: 0.6641 - val_loss: 0.7329 - val_accuracy: 0.5312\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 11s 4s/step - loss: 0.6408 - accuracy: 0.6719 - val_loss: 0.7177 - val_accuracy: 0.5938\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.6320 - accuracy: 0.6484 - val_loss: 0.6647 - val_accuracy: 0.6875\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-222531789aa8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m classifier.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m#steps_per_epoch=1569,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#steps_per_epoch=49, #??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nUnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fdf74d002c0>\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/image_utils.py\", line 423, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3030, in open\n    raise UnidentifiedImageError(\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fdf74d002c0>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_2284]"
          ]
        }
      ],
      "source": [
        "classifier.fit(\n",
        "        train_generator,\n",
        "        #steps_per_epoch=1569,\n",
        "        #steps_per_epoch=49, #??\n",
        "        steps_per_epoch=4,\n",
        "        epochs=10,\n",
        "        validation_data=test_generator,\n",
        "        #validation_steps=387\n",
        "        #validation_steps=12\n",
        "        validation_steps=1) #??\n",
        "try:\n",
        "  print()\n",
        "except:\n",
        "  print(\"An exception occurred\")\n",
        "  \n",
        "classifier.save_weights('/content/gdrive/My Drive/Google Colab Folder/first_try.h5')  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}