{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akutayaydin/Magnimind-5.1-DeepLearning/blob/main/0_WarmUp1CNNExample1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmy5qTKlB2CI"
      },
      "source": [
        "# CNN Example 1\n",
        "For this example, we have images of cars and flowers, which have been divided into training and testing sets, and we have to build a CNN that identifies whether an image is a car or a flower."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lgp8guPB2CM"
      },
      "source": [
        "### Step 1: Import the numpy library and the necessary Keras libraries and classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "upl626WiB2CN"
      },
      "outputs": [],
      "source": [
        "# Import the Libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "from tensorflow import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYEzxW4VB2CO"
      },
      "source": [
        "### Step 2: Now, set a seed and initiate the model with the `Sequential` class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "afwVGvUBB2CP"
      },
      "outputs": [],
      "source": [
        "#set a seed\n",
        "seed = 1\n",
        "np.random.seed(seed)\n",
        "random.set_seed(seed)\n",
        "\n",
        "# Initialising the CNN\n",
        "classifier = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj0rBoXqB2CP"
      },
      "source": [
        "### Step 3: Add the first layer of the CNN, set the input shape to (64, 64, 3), the dimension of each image, and set the activation function as a ReLU:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Conv2D(10,kernel_size =2, activation = 'relu',input_shape = (64,64,3)))"
      ],
      "metadata": {
        "id": "AgeuksX0-HMg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzoUpnCSB2CP"
      },
      "source": [
        "### Step 4: Now, add the pooling layer with the image size as 2x2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(MaxPool2D(pool_size =(2,2)))"
      ],
      "metadata": {
        "id": "9V-N27VN9B4Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEWIVnACB2CQ"
      },
      "source": [
        "### Step 5: Flatten the output of the pooling layer by adding a flattening layer to the CNN model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qxsUjB8nB2CQ"
      },
      "outputs": [],
      "source": [
        "classifier.add(Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqt_0VFFB2CQ"
      },
      "source": [
        "### Step 6: Add the first Dense layer of the MLP. \n",
        "Here, 128 is the output of the number of nodes. As a good practice, 128 is good to get started. activation is relu. As a good practice, the power of two is preferred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-j1PqTa8B2CQ"
      },
      "outputs": [],
      "source": [
        "classifier.add(Dense(128,activation = 'relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGhBSPmHB2CQ"
      },
      "source": [
        "### Step 7: Add the output layer of the MLP.\n",
        "This is a binary classification problem, so the size is 1 and the activation is `sigmoid`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mwvnRNVZB2CR"
      },
      "outputs": [],
      "source": [
        "classifier.add(Dense(1,activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9dg60CvB2CR"
      },
      "source": [
        "### Step 8: Compile the network\n",
        "Use an adam optimizer and compute the accuracy during the training process "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "9aOmePUeBNJC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhIQ1s91B2CR"
      },
      "source": [
        "### Step 9: Create training and test data generators. \n",
        "- Rescale the training and test images by `1/255` so that all the values are between `0` and `1`.\n",
        "- Set these parameters for the training data generators only \n",
        " - `shear_range=0.2`, `zoom_range=0.2`, and `horizontal_flip=True`\n",
        " \n",
        " - https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfolwzTsRuF7",
        "outputId": "168352aa-32d1-4aaa-e96a-6b62a69b743e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "t7sXo40sB2CS"
      },
      "outputs": [],
      "source": [
        "mypath='/content/gdrive/My Drive/Google Colab Folder/'\n",
        "mypath_testdata = '/content/gdrive/My Drive/Google Colab Folder/train'\n",
        "mypath_validationdata = '/content/gdrive/My Drive/Google Colab Folder/test'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check for any file corruptions\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "for name in os.listdir(mypath_testdata):\n",
        "  dir = os.path.join(mypath_testdata, name)\n",
        "  if os.path.isdir(dir):\n",
        "    print('Dir name:' + str(name))\n",
        "    for fname in os.listdir(dir):\n",
        "      try:   \n",
        "        img = Image.open(str(dir) + '/'+ str(fname))\n",
        "        img.verify()  # verify that it is, in fact an image\n",
        "      except:\n",
        "        print('Bad file: ' + str(fname))\n",
        "\n",
        "for name in os.listdir(mypath_validationdata):\n",
        "  dir = os.path.join(mypath_validationdata, name)\n",
        "  if os.path.isdir(dir):\n",
        "    print('Dir name:' + str(name))\n",
        "    for fname in os.listdir(dir):\n",
        "      try:   \n",
        "        img = Image.open(str(dir) + '/'+ str(fname))\n",
        "        img.verify()  # verify that it is, in fact an image\n",
        "      except:\n",
        "        print('Bad file: ' + str(fname))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JJwUJWiNGxJ",
        "outputId": "583d5123-9304-444d-fa01-6043c23f4080"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dir name:car\n",
            "Bad file: car1115.jpg\n",
            "Dir name:flower\n",
            "Dir name:car\n",
            "Dir name:flower\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.utils import array_to_img, img_to_array, load_img"
      ],
      "metadata": {
        "id": "29x1XRL9VRk0"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define batch size here\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1. /255,\n",
        "    shear_range =0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1. /255)"
      ],
      "metadata": {
        "id": "9pZWwYUzPFiI"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RqwiPw1B2CR"
      },
      "source": [
        "### Step 10: Create a training set from the training set folder.\n",
        "'training_set' is the folder where our data has been placed. Our CNN model has an image size of `64x64`, so the same size should be passed here too. `batch_size` is the number of images in a single batch, which is `32`. `Class_mode` is set to binary since we are working on binary classifiers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train data generation starts here\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory = mypath_testdata,\n",
        "    target_size = (64,64), #resize all images\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF_vCK-lB_UD",
        "outputId": "9a5483ea-b2d9-40cb-8e07-a97a1d87ec69"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1568 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Llh-3cHRB2CS"
      },
      "source": [
        "### Step 11: Repeat step 10 for the test set \n",
        "while setting the folder to the location of the test images, that is, 'test_set'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gel5EYa7B2CS",
        "outputId": "3336902a-b46b-4cf1-dca6-7128646c28dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 387 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "#Test data generation starts here\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory = mypath_validationdata,\n",
        "    target_size = (64,64),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv8y1u9ZB2CS"
      },
      "source": [
        "### Step 12: Finally, fit the data. \n",
        "Set the `steps_per_epoch` to `STEP_SIZE_TRAIN` and the `validation_steps` to `STEP_SIZE_TEST`. \n",
        "\n",
        "Why do we need `steps_per_epoch` ?\n",
        "\n",
        "Keep in mind that a Keras data generator is meant to loop infinitely — it should never return or exit.\n",
        "\n",
        "Since the function is intended to loop infinitely, Keras has no ability to determine when one epoch starts and a new epoch begins.\n",
        "\n",
        "Therefore, we compute the `steps_per_epoch` value as the total number of training data points divided by the batch size. Once Keras hits this step count it knows that it’s a new epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsNWVdQkB2CT",
        "outputId": "09f83c24-831b-4c19-c34a-f7b2e66104ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 11s 209ms/step - loss: 0.6447 - accuracy: 0.6371 - val_loss: 0.5869 - val_accuracy: 0.6719\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 9s 182ms/step - loss: 0.5291 - accuracy: 0.7366 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 10s 211ms/step - loss: 0.4738 - accuracy: 0.7838 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 10s 204ms/step - loss: 0.4578 - accuracy: 0.7825 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 9s 180ms/step - loss: 0.4460 - accuracy: 0.7876 - val_loss: 0.4706 - val_accuracy: 0.7865\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 10s 206ms/step - loss: 0.4280 - accuracy: 0.7997 - val_loss: 0.4718 - val_accuracy: 0.7891\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 10s 212ms/step - loss: 0.4114 - accuracy: 0.8131 - val_loss: 0.4777 - val_accuracy: 0.7839\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 10s 204ms/step - loss: 0.3911 - accuracy: 0.8170 - val_loss: 0.4853 - val_accuracy: 0.7812\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 9s 189ms/step - loss: 0.3887 - accuracy: 0.8214 - val_loss: 0.4601 - val_accuracy: 0.7917\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 10s 211ms/step - loss: 0.3685 - accuracy: 0.8393 - val_loss: 0.4860 - val_accuracy: 0.7812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=49, #QUESTION??\n",
        "        epochs=10,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=12) #QUESTION??\n",
        "\n",
        "classifier.save_weights('/content/gdrive/My Drive/Google Colab Folder/first_try.h5')  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}